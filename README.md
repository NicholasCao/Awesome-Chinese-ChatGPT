# ğŸ§  Awesome-Chinese-ChatGPT-Implement
æ”¶å½•å®ç°ä¸­æ–‡ç‰ˆChatGPTçš„å„ç§å¼€æºæŠ€æœ¯è·¯çº¿ï¼Œæ•°æ®åŠå…¶ä»–èµ„æ–™

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
![](https://img.shields.io/github/last-commit/NicholasCao/Awesome-Chinese-ChatGPT?color=green)

<img src="assets/chatgpt.jpg" width="44.5%" div align=center /> <img src="assets/chatgpt2.svg" width="45%" div align=center />

Three steps to ChatGPT: 
1. LLM-pretrain
2. Instruction tuning and code continual pretrain
3. RLHF (SFT, RM, PPO-RL)

å…·ä½“æŠ€æœ¯å¯å‚è€ƒ [dalinvip/Awesome-ChatGPT](https://github.com/dalinvip/Awesome-ChatGPT)

## Data

- [BELLEæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†](https://github.com/LianjiaTech/BELLE/tree/main/1.5M)(1.5M)
- [BELLE10Mä¸­æ–‡æ•°æ®é›†](https://github.com/LianjiaTech/BELLE/tree/main/10M), åŒ…å«0.25Mæ•°å­¦æŒ‡ä»¤æ•°æ®é›†å’Œ0.8Må¤šè½®ä»»åŠ¡å¯¹è¯æ•°æ®é›†
- [InstructionWild](https://github.com/XueFuzhao/InstructionWild): Colossal AI æ”¶é›†çš„ä¸­è‹±åŒè¯­æ•°æ®é›†(104K)
- [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM): GPT-4æ ‡æ³¨çš„ä¸­è‹±åŒè¯­æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œpromptæ¥è‡ª[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)ã€‚
- [ShareGPT](https://sharegpt.com/): ChatGPTç”¨æˆ·åˆ†äº«çš„èŠå¤©æ•°æ®ï¼Œå¤§éƒ¨åˆ†ä¸ºè‹±æ–‡æ•°æ®ï¼Œæ’ä»¶ç»´æŠ¤è€…ç›®å‰å·²ç»å…³é—­äº†å…¬å¼€è·å–æ•°æ®çš„æ¥å£ã€‚
- [CAMEL](https://github.com/lightaime/camel#data-hosted-on-hugging-face): å¯¹è¯å¼æŒ‡ä»¤è·Ÿéšæ•°æ®é›†ï¼Œå¹¶å°†è‹±æ–‡æ•°æ®ç¿»è¯‘åˆ°10ç§åŒ…å«ä¸­æ–‡çš„ä¸åŒè¯­è¨€ã€‚

## æ¨¡å‹

### [BELLE](https://github.com/LianjiaTech/BELLE)

å‚ç…§[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)(SFT only)ï¼Œå¯¹BLOOMZå’ŒLLAMAè¿›è¡Œå¾®è°ƒã€‚

### [MOSS](https://github.com/txsun1997/MOSS)
<!-- ![MOSS](./assets/moss.jpg) -->
<img src="assets/moss.jpg" width="40%" height="50%" div align=center />

å¤æ—¦å¤§å­¦å›¢é˜Ÿç ”å‘çš„å®ç°æ–¹æ¡ˆï¼Œå›¾æ¥è‡ªé‚±è€å¸ˆçš„åˆ†äº«ã€‚(Backboneä¸º20Bå¤§æ¨¡å‹)

### [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)

æ¸…åå¤§å­¦å›¢é˜ŸåŸºäº[GLM](https://github.com/THUDM/GLM)çš„å®ç°æ–¹æ¡ˆï¼Œå…¶6Bæ¨¡å‹å·²å…¬å¸ƒæƒé‡ã€‚

### [ColossalChat](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat)
Colossal-AIå®ç°RLHF for LLMæ–¹æ¡ˆ(åŸºäºLLaMA)ã€‚

### [DeepSpeed Chat](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-chat)
å¾®è½¯åŸºäºDeepSpeedå¼€æºçš„ç®€å•ã€å¿«é€Ÿä¸”ç»æµå®æƒ çš„RLHFè®­ç»ƒæ–¹æ¡ˆã€‚

## LLM(åŸºåº§)
### LLaMA
[LLaMA](https://github.com/facebookresearch/llama): Open and Efficient Foundation Language Modelsï¼ŒFacebook/Metaå¼€æºçš„LLMï¼Œä¸­æ–‡è¯è¡¨è¾ƒå°ã€‚

### BLOOM
Huggingfaceå¼€æºçš„LLMæ¨¡å‹ã€‚
- [BLOOM](https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/bloom#overview)
- [BLOOMZ](https://huggingface.co/bigscience/bloomz): æŒ‡ä»¤å¾®è°ƒç‰ˆçš„BLOOM

### GLM
æ¸…åå¤§å­¦å¼€æºçš„ä½¿ç”¨è‡ªå›å½’å¡«ç©ºç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒçš„é€šç”¨è¯­è¨€æ¨¡å‹[GLM](https://github.com/THUDM/GLM)

## å…¶ä»–ç›¸å…³å¼€æºé¡¹ç›®
å…¶ä½™ä¼˜ç§€å¼€æºé¡¹ç›®ï¼Œå¤§éƒ¨åˆ†ä¸ºçº¯è‹±æ–‡

- [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca): LLAMA-7B SFT
- [Vicuna](https://github.com/lm-sys/FastChat): LLAMA-7b&13B SFTï¼Œæ•°æ®æ¥è‡ªShareGPT
- [Baize](https://github.com/project-baize/baize-chatbot): LLAMAèŠå¤©å¾®è°ƒï¼Œæ•°æ®é‡‡é›†è‡ªChatGPT self-chat
- [LoRA](https://github.com/microsoft/LoRA): popularä½æˆæœ¬LLMå‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ¡ˆï¼Œå·²é›†æˆåˆ°[PEFT](https://github.com/huggingface/peft)
- [self-instruct](https://github.com/yizhongw/self-instruct): ä½æˆæœ¬æ”¶é›†æŒ‡ä»¤å¾®è°ƒæ•°æ®
- [UltraChat](https://github.com/thunlp/UltraChat): ChatGPTç”Ÿæˆçš„å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œç›®å‰åªåŒ…å«è‹±æ–‡ã€‚
- [Dolly](https://github.com/databrickslabs/dolly): åŸºäºEleutherAI/pythia-12bçš„æŒ‡ä»¤å¾®è°ƒï¼ŒåŒ…å«é¦–ä¸ªå¼€æºçš„äººå·¥æ ‡æ³¨æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚

## Contribution
å¦‚æœä½ åˆ›å»ºæˆ–å‘ç°äº†ä»»ä½•å…³äºå®ç°ä¸­æ–‡ChatGPTçš„ä¼˜ç§€èµ„æºï¼Œè¯·åˆ›å»ºIssueæˆ–PRæ¥è´¡çŒ®è¿™ä¸ªä»“åº“!

If you created or found any awesome resource about Chinese ChatGPT, feel free to create issues or PRs to contribute to this repository!
